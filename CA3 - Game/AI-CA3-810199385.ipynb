{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h1>پروژه سوم</h1>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h2>پیاده‌سازی</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle\n",
    "import math\n",
    "import random\n",
    "from time import sleep\n",
    "from copy import deepcopy\n",
    "from enum import Enum\n",
    "from typing import Union\n",
    "from sys import argv\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERTICES_COUNT = 6\n",
    "SLEEP_TIME = 1.5\n",
    "\n",
    "Line = tuple[int, int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player(Enum):\n",
    "    RED = 'red'\n",
    "    BLUE = 'blue'\n",
    "\n",
    "    def __invert__(self) -> 'Player':\n",
    "        return Player.RED if self == Player.BLUE else Player.BLUE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "کلاس\n",
    "Player\n",
    "که نوعی \n",
    "enum\n",
    "است، برای حذف کد تکراری از کلاس\n",
    "Sim\n",
    "اضافه شده است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimaxType(Enum):\n",
    "    MIN = 0\n",
    "    MAX = 1\n",
    "\n",
    "    def __invert__(self) -> 'MinimaxType':\n",
    "        return MinimaxType.MIN if self == MinimaxType.MAX else MinimaxType.MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(player_moves: dict[Player, list[Line]]) -> tuple[Union[Player, None], Union[tuple[Line, Line, Line], None]]:\n",
    "    for color, moves in player_moves.items():\n",
    "        if len(moves) < 3:\n",
    "            continue\n",
    "        for i in range(0, len(moves) - 2):\n",
    "            for j in range(i + 1, len(moves) - 1):\n",
    "                for k in range(j + 1, len(moves)):\n",
    "                    if len(set(moves[i] + moves[j] + moves[k])) == 3:\n",
    "                        return ~color, (moves[i], moves[j], moves[k])\n",
    "    return None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "تابع فوق به ازای هر 3 خطی که هر بازیکن گذاشته است، تعداد رئوس تشکیل‌دهنده این 3 خط را بدست می‌آورد و در صورتی که این مقدار برابر با 3 باشد، آن را یک مثلث به حساب آورده و برنده بازی را مشخص می‌کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimGui:\n",
    "    Dot = tuple[float, float]\n",
    "\n",
    "    def __init__(self, title: str, width: int, height: int, vertices_count: int):\n",
    "        self._screen = turtle.Screen()\n",
    "        self._screen.setup(width, height)\n",
    "        self._screen.title(title)\n",
    "        self._screen.bgcolor(0.117, 0.117, 0.117)\n",
    "        self._screen.setworldcoordinates(-1.5, -1.5, 1.5, 1.5)\n",
    "        self._screen.tracer(0, 0)\n",
    "        turtle.hideturtle()\n",
    "        self._vertices_count = vertices_count\n",
    "        self._gen_dots()\n",
    "        self._draw_board()\n",
    "\n",
    "    def _gen_dots(self) -> None:\n",
    "        self._dots = []\n",
    "        for angle in range(0, 360, 360 // self._vertices_count):\n",
    "            self._dots.append((math.cos(math.radians(angle)),\n",
    "                               math.sin(math.radians(angle))))\n",
    "\n",
    "    def _draw_dot(self, x: float, y: float, color: str) -> None:\n",
    "        turtle.up()\n",
    "        turtle.goto(x, y)\n",
    "        turtle.color(color)\n",
    "        turtle.dot(15)\n",
    "\n",
    "    def _draw_line(self, p1: Dot, p2: Dot, color: str, pensize: int = 6) -> None:\n",
    "        turtle.up()\n",
    "        turtle.pensize(pensize)\n",
    "        turtle.goto(p1)\n",
    "        turtle.down()\n",
    "        turtle.color(color)\n",
    "        turtle.goto(p2)\n",
    "\n",
    "    def _draw_board(self) -> None:\n",
    "        for dot in self._dots:\n",
    "            self._draw_dot(dot[0], dot[1], 'dark gray')\n",
    "\n",
    "    def _lineToDots(self, line: Line) -> tuple[Dot, Dot]:\n",
    "        return ((math.cos(math.radians(line[0] * 360 // self._vertices_count)),\n",
    "                 math.sin(math.radians(line[0] * 360 // self._vertices_count))),\n",
    "                (math.cos(math.radians(line[1] * 360 // self._vertices_count)),\n",
    "                 math.sin(math.radians(line[1] * 360 // self._vertices_count))))\n",
    "\n",
    "    def draw(self, player_moves: dict[Player, list[Line]] = {}) -> None:\n",
    "        turtle.clear()\n",
    "        self._draw_board()\n",
    "        for color, moves in player_moves.items():\n",
    "            for move in moves:\n",
    "                self._draw_line(*self._lineToDots(move), color.value)\n",
    "        self._screen.update()\n",
    "\n",
    "    def show_triangle(self, triangle: tuple[Line, Line, Line]) -> None:\n",
    "        for line in triangle:\n",
    "            self._draw_line(*self._lineToDots(line), 'white', 3)\n",
    "        self._screen.update()\n",
    "\n",
    "    def close(self) -> None:\n",
    "        self._screen.bye()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "تابع \n",
    "show_triangle\n",
    "در این کلاس، برای نشان دادن مثلثی که باعث باخت یک بازیکن شده است، اضافه شده است. این تابع مثلث ساخته شده را به رنگ سفید درمی‌آورد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimaxNode:\n",
    "    _type: MinimaxType\n",
    "    _value: float\n",
    "    _children: dict[Line, 'MinimaxNode']\n",
    "    _parent: Union['MinimaxNode', None]\n",
    "    _move: Union[Line, None]\n",
    "    _player: Player\n",
    "    _depth: int\n",
    "    _max_depth: int\n",
    "    _prune: bool\n",
    "    _alpha: float\n",
    "    _beta: float\n",
    "    _available_moves: list[Line]\n",
    "    _player_moves: dict[Player, list[Line]]\n",
    "\n",
    "    def __init__(self, parent: Union['MinimaxNode', None] = None, available_moves: list[Line] = [],\n",
    "                 player_moves: dict[Player, list[Line]] = {}, prune: bool = False, max_depth: int = 1):\n",
    "        self._parent = parent\n",
    "        self._move = None\n",
    "        self._children = {}\n",
    "        self._value = 0\n",
    "        self._type = MinimaxType.MAX if not parent else ~parent._type\n",
    "        self._depth = 0 if not parent else parent._depth + 1\n",
    "        self._max_depth = parent._max_depth if parent else max_depth\n",
    "        self._player = Player.RED if not parent else ~parent._player\n",
    "        self._alpha = -math.inf if not parent else parent._alpha\n",
    "        self._beta = math.inf if not parent else parent._beta\n",
    "        self._available_moves = deepcopy(parent._available_moves) if parent else deepcopy(available_moves)\n",
    "        self._player_moves = {player: deepcopy(moves) for player, moves in parent._player_moves.items()} if parent else \\\n",
    "            {player: deepcopy(moves) for player, moves in player_moves.items()}\n",
    "        self._prune = parent._prune if parent else prune\n",
    "\n",
    "    def _evaluate(self) -> float:\n",
    "        w = winner(self._player_moves)[0]\n",
    "        if w is not None:\n",
    "            return math.inf if w == Player.RED else -math.inf\n",
    "        h = 0\n",
    "        for move in self._available_moves:\n",
    "            res = winner({self._player: self._player_moves[self._player] + [move]})[0]\n",
    "            if res:\n",
    "                h -= 1 # player is losing\n",
    "            res = winner({~self._player: self._player_moves[~self._player] + [move]})[0]\n",
    "            if res:\n",
    "                h += 1 # player is winning\n",
    "        return h if self._player == Player.RED else -h\n",
    "\n",
    "    def _minimax(self) -> tuple[float, int]:\n",
    "        if winner(self._player_moves)[0] is not None or self._depth == self._max_depth:\n",
    "            self._value = self._evaluate()\n",
    "            return self._value, self._depth\n",
    "        self._value = -math.inf if self._type == MinimaxType.MAX else math.inf\n",
    "        optimal_depth = 0\n",
    "        for move in deepcopy(self._available_moves):\n",
    "            self._available_moves.remove(move)\n",
    "            self._player_moves[self._player].append(move)\n",
    "            child = MinimaxNode(self)\n",
    "            self._children[move] = child\n",
    "            val, dep = child._minimax()\n",
    "\n",
    "            if self._type == MinimaxType.MAX:\n",
    "                if val > self._value:\n",
    "                    self._value = val\n",
    "                    self._move = move\n",
    "                    optimal_depth = dep\n",
    "                elif val == self._value and dep > optimal_depth:\n",
    "                    self._move = move\n",
    "                    optimal_depth = dep\n",
    "                self._alpha = max(self._alpha, self._value)\n",
    "            else:\n",
    "                if val < self._value:\n",
    "                    self._value = val\n",
    "                    self._move = move\n",
    "                    optimal_depth = dep\n",
    "                elif val == self._value and dep > optimal_depth:\n",
    "                    self._move = move\n",
    "                    optimal_depth = dep\n",
    "                self._beta = min(self._beta, self._value)\n",
    "\n",
    "            if self._prune and self._alpha >= self._beta:\n",
    "                break\n",
    "\n",
    "            self._player_moves[self._player].remove(move)\n",
    "            self._available_moves.append(move)\n",
    "\n",
    "        return self._value, optimal_depth\n",
    "\n",
    "    def get_best_move(self) -> Line:\n",
    "        self._minimax()\n",
    "        return self._move  # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "برای انجام الگوریتم\n",
    "Minimax\n",
    "از کلاس\n",
    "MinimaxNode\n",
    "استفاده شده که نتیجه آن، ساخت درخت\n",
    "Minimax\n",
    "است.<br/>\n",
    "<h3>هیوریستیک</h3>\n",
    "برای هیوریستیک باید احتمال تشکیل مثلث و باخت هر بازیکن را در نظر بگیریم. به همین دلیل، ابتدا مقدار هیوریستیک را برابر با صفر می‌گذاریم و سپس به ازای هر خط در\n",
    "available_moves،\n",
    "اگر بازیکن با انتخاب این خط یک مثلث تشکیل می‌داد، یک واحد از مقدار هیوریستیک کم می‌کنیم و اگر حریف با انتخاب این خط باعث تشکیل مثلث می‌شد، یک واحد به هیوریستیک اضافه می‌کنیم. در نهایت اگر بازیکن مرحله فعلی قرمز بود، مقدار هیوریستیک، و اگر آبی بود، (استیت مینیمم‌کننده)، قرینه این مقدار را برمی‌گردانیم. لازم به ذکر است که اگر در استیت فعلی برنده و بازنده مشخص شده باشد، این تابع، اگر برنده قرمز باشد مقدار\n",
    "&infin;\n",
    "و اگر برنده آبی باشد، مقدار\n",
    "&infin;-\n",
    "را برمی‌گرداند.<br/><br/>\n",
    "<b>‌پس از چند بار انجام الگوریتم مشخص شد که این الگوریتم در عمق 1 و 3 به خوبی عمل می‌کند ولی در عمق‌های 5 و 7، احتمال برد بسیار کاهش می‌یابد. پس از بررسی‌های مکرر متوجه شدم که مشکل این است که در عمق‌های بالا، برنده و بازنده در اکثر\n",
    "nodeهای\n",
    "درخت به صورت قطعی مشخص شده‌اند و در نتیجه مقادیر اکثر شاخه‌ها \n",
    "&infin;\n",
    "و یا\n",
    "&infin;-\n",
    "خواهد بود. این\n",
    "agent\n",
    "با انجام الگوریتم\n",
    "Minimax\n",
    "فرض می‌کند که حریف نیز کاملا هوشمندانه عمل می‌کند در صورتی که حریف کاملا رندوم عمل می‌کند. همین دلیل باعث می‌شود که \n",
    "agent\n",
    "زمانی که به یک\n",
    "stateای\n",
    "می‌رسد که مقدار تمامی شاخه‌های آن \n",
    "&infin;-\n",
    "است، تفاوتی بین آن‌ها نبیند و یکی از آن‌ها را انتخاب کند. شاخه انتخاب شده می‌تواند باعث شود که بازیکن قرمز در مرحله‌ای ببازد که هنوز حرکت دیگری وجود دارد. این مورد در حالتی است که اگر \n",
    "agent\n",
    "مسیر طولانی‌تری را انتخاب می‌کرد، ممکن بود با عملکرد رندوم بازیکن آبی به برد برسد. به همین دلیل تصمیم گرفتم عمق برگی که امتیازش به کمک تابع\n",
    "evaluate_\n",
    "محاسبه می‌شود را نیز در الگوریتم دخیل کنم که اگر در یک \n",
    "state\n",
    "چند شاخه با مقدار یکسان قرار داشت، شاخه‌ای انتخاب شود که عمق برگی که به \n",
    "&infin;-\n",
    "رسیده است بیشتر باشد. همین مورد باعث افزایش احتمال برد بازیکن قرمز در عمق‌های بالا می‌شود.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sim:\n",
    "    _gui: Union[SimGui, None]\n",
    "    _turn: Player\n",
    "    _player_moves: dict[Player, list[Line]]\n",
    "    _available_moves: list[Line]\n",
    "    _minimax_depth: int\n",
    "    _prune: bool\n",
    "\n",
    "    def __init__(self, minimax_depth: int, prune: bool, gui: bool):\n",
    "        self._prune = prune\n",
    "        self._minimax_depth = minimax_depth\n",
    "        self._gui = SimGui('Game of Sim', 800, 800, VERTICES_COUNT) if gui else None\n",
    "\n",
    "    def _initialize(self) -> None:\n",
    "        self._available_moves = []\n",
    "        for i in range(0, VERTICES_COUNT):\n",
    "            for j in range(i, VERTICES_COUNT):\n",
    "                if i != j:\n",
    "                    self._available_moves.append((i, j))\n",
    "        self._turn = random.choice([Player.RED, Player.BLUE])\n",
    "        self._player_moves = {player: [] for player in Player}\n",
    "        if self._gui:\n",
    "            self._gui.draw()\n",
    "\n",
    "    def _swap_turn(self) -> None:\n",
    "        self._turn = ~self._turn\n",
    "\n",
    "    def _minimax(self) -> tuple[Line, float]:\n",
    "        root = MinimaxNode(available_moves=self._available_moves, player_moves=self._player_moves,\n",
    "                           prune=self._prune, max_depth=self._minimax_depth)\n",
    "        return root.get_best_move(), root._value\n",
    "\n",
    "    def _enemy_move(self) -> Line:\n",
    "        return random.choice(self._available_moves)\n",
    "\n",
    "    def _game_over(self) -> tuple[Union[Player, None], Union[tuple[Line, Line, Line], None]]:\n",
    "        return winner(self._player_moves)\n",
    "\n",
    "    def play(self) -> Player:\n",
    "        self._initialize()\n",
    "        while True:\n",
    "            selection = self._minimax()[0] if self._turn == Player.RED else self._enemy_move()\n",
    "            selection = tuple(sorted(selection))\n",
    "\n",
    "            if selection in self._player_moves.values():\n",
    "                raise Exception(\"Duplicate Move!\")\n",
    "\n",
    "            self._player_moves[self._turn].append(selection)\n",
    "            self._available_moves.remove(selection)\n",
    "            self._swap_turn()\n",
    "            if self._gui:\n",
    "                self._gui.draw(self._player_moves)\n",
    "                sleep(SLEEP_TIME)\n",
    "            res = self._game_over()\n",
    "            if res[0]:\n",
    "                if self._gui:\n",
    "                    self._gui.show_triangle(res[1])  # type: ignore\n",
    "                    sleep(SLEEP_TIME)\n",
    "                return res[0]\n",
    "\n",
    "    def close(self) -> None:\n",
    "        if self._gui:\n",
    "            self._gui.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWinChanceAndTime(depth: int, prune: bool, test_count: int) -> None:\n",
    "    game = Sim(minimax_depth=depth, prune=prune, gui=False)\n",
    "    start = timer()\n",
    "    result = {p: 0 for p in Player}\n",
    "    for i in range(test_count):\n",
    "        print(f\"Processing Test {i + 1}/{test_count}\", end=\"\\r\")\n",
    "        res = game.play()\n",
    "        result[res] += 1\n",
    "    end = timer()\n",
    "    print(result)\n",
    "    print(f\"Depth: {depth}, Prune: {prune}\")\n",
    "    print(f\"Time: {(end - start) / test_count:.4f}s\")\n",
    "    print(f\"Win chance: {result[Player.RED] * 100 // test_count}%\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h2>بررسی نتایج</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner:  Player.RED\n"
     ]
    }
   ],
   "source": [
    "game = Sim(minimax_depth=5, prune=True, gui=True)\n",
    "res = game.play()\n",
    "print(\"Winner: \", res)\n",
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<Player.RED: 'red'>: 99, <Player.BLUE: 'blue'>: 1}\n",
      "Depth: 1, Prune: False\n",
      "Time: 0.0047s\n",
      "Win chance: 99%\n",
      "\n",
      "{<Player.RED: 'red'>: 99, <Player.BLUE: 'blue'>: 1}\n",
      "Depth: 3, Prune: False\n",
      "Time: 0.4792s\n",
      "Win chance: 99%\n",
      "\n",
      "{<Player.RED: 'red'>: 50, <Player.BLUE: 'blue'>: 0}\n",
      "Depth: 5, Prune: False\n",
      "Time: 45.8823s\n",
      "Win chance: 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calcWinChanceAndTime(1, False, 100)\n",
    "calcWinChanceAndTime(3, False, 100)\n",
    "calcWinChanceAndTime(5, False, 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "در این بخش چون زمان انجام الگوریتم با عمق 5 و بدون هرس بسیار زیاد است، این یک مورد را به جای 100 بار، 50 بار اجرا کردم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<Player.RED: 'red'>: 99, <Player.BLUE: 'blue'>: 1}\n",
      "Depth: 1, Prune: True\n",
      "Time: 0.0047s\n",
      "Win chance: 99%\n",
      "\n",
      "{<Player.RED: 'red'>: 98, <Player.BLUE: 'blue'>: 2}\n",
      "Depth: 3, Prune: True\n",
      "Time: 0.0894s\n",
      "Win chance: 98%\n",
      "\n",
      "{<Player.RED: 'red'>: 100, <Player.BLUE: 'blue'>: 0}\n",
      "Depth: 5, Prune: True\n",
      "Time: 1.1692s\n",
      "Win chance: 100%\n",
      "\n",
      "{<Player.RED: 'red'>: 100, <Player.BLUE: 'blue'>: 0}\n",
      "Depth: 7, Prune: True\n",
      "Time: 12.4892s\n",
      "Win chance: 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calcWinChanceAndTime(1, True, 100)\n",
    "calcWinChanceAndTime(3, True, 100)\n",
    "calcWinChanceAndTime(5, True, 100)\n",
    "calcWinChanceAndTime(7, True, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "همانطور که مشاهده می‌شود، زمان اجرای تمامی حالات به مراتب نسبت به حالتی که هرس را انجام نمی‌دادیم، کاهش یافته است.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "احتمال برد در تمامی حالات بالای 98 درصد است که نشان‌دهنده عملکرد مناسب الگوریتم و هیوریستیک مورد استفاده است.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<h2>سوالات</h2>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "<ol>\n",
    "    <li>یک هیوریستیک خوب باید بتواند با احتمال بالایی، برد یا باخت بازیکن را پیش‌بینی کند که بتوانیم بهترین مسیر را از ابتدا پیدا کنیم. در این سوال برنده و بازنده با تشکیل مثلث مشخص می‌شوند و به همین دلیل بهترین روش این است که روی احتمال تشکیل مثلث توسط هر بازیکن مانور بدهیم. این هیوریستیک به ازای هر مثلثی که حریف بتواند در حرکت بعدی‌اش تشکیل دهد یک امتیاز مثبت، و به ازای هر مثلثی که بازیکن فعلی بتواند در حرکت بعدی‌اش تشکیل دهد، یک امتیاز منفی در نظر می‌گیرد. و به همین دلیل باعث می‌شود حالتی را انتخاب کنیم که احتمال بازنده بودن خودمان (برنده شدن حریف) کمینه شود. یک روش دیگر این است که مثلث‌های قابل تشکیل توسط حریف را محاسبه نکنیم و فقط به ازای تشکیل هر مثلث توسط خودمان، یک امتیاز منفی در نظر بگیریم. با امتحان کردن این هیوریستیک متوجه می‌شویم که احتمال برد کاهش می‌یابد. روش دیگر این است که مجموعه درجه رئوس را محاسبه کنیم که در این حالت اگر دو خط کاملا با فاصله از همدیگر قرار بگیرند، مقدار هیوریستیک برابر با 4 خواهد شد و اگر دو خط مورد نظر در یک راس مشترک باشند نیز، مقدار هیوریستیک برابر با 4 خواهد بود در صورتی که در حالت دوم، احتمال تشکیل مثلث بیشتر است. در همین مثال، هیوریستیک پیاده‌سازی شده برای حالت اول مقدار 0 و برای حالت دوم مقدار 1 را برمی‌گرداند.</li><br/>\n",
    "    <li>وقتی عمق افزایش می‌یابد، بدیهی‌ست که تعداد گره‌های مشاهده شده افزایش پیدا می‌کند و در نتیجه زمان الگوریتم نیز بیشتر می‌شود. برای مثال اگر بخواهیم تا عمق \n",
    "    n-ام\n",
    "    را بدون هرس کردن محاسبه کنیم، تعداد گره‌های مشاهده شده به صورت زیر بدست می‌آید. همچنین، به دلیل اینکه با افزایش عمق احتمال اینکه برنده و بازنده بازی به صورت قطعی مشخص شود بیشتر می‌شود، به صورت دقیق‌تری می‌توانیم مسیر مناسب را پیش‌بینی کنیم.\n",
    "    همانطور که پیش‌تر گفته شد، اگر عمق برگ‌ها را در الگوریتم دخیل نکنیم، شانس پیروزی کاهش می‌یابد، اما با دخیل کردن این مورد، احتمال برد به مقدار زیادی افزایش می‌یابد.</li><br/>\n",
    "    <li>زمانی که از هرس کردن استفاده می‌کنیم، ترتیب ساخت درخت اهمیت زیادی دارد زیرا ممکن است در یک ترتیب تمام \n",
    "    stateها\n",
    "    مانند حالتی که هرس نمی‌کنیم پیمایش شوند و در ترتیب دیگری، ممکن است تعداد زیادی از\n",
    "    stateها \n",
    "    هرس شوند و باعث کاهش زمان انجام الگوریتم شود. در این سوال ترتیب اولیه اهمیتی ندارد زیرا تمام رئوس و خط‌ها یکسان هستند و هیچ اختلافی بین هیچ جفتی از آن‌ها وجود ندارد. اما لازم است که در تمام مراحل همین ترتیب را حفظ کنیم زیرا طبق الگوریتم، اگر چند حالت با امتیاز مشابه وجود داشته باشد، همواره اولین حالت انتخاب می‌شود و در صورتی که ترتیب اولیه حفظ شود، اکثر یال‌ها از رئوس با شماره کوچک‌تر خارج می‌شود که باعث نزدیک شدن این رئوس به تشکیل مثلث می‌شود. به همین دلیل در هرس آلفا و بتا نیز ممکن است قبل از پیمایش کل درخت، مسیر مناسب را پیدا کنیم و نیاز به ساخت کل درخت نباشد.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$statesCount = \\dfrac{(15 - {currentDepth})!}{(15 - {currentDepth} - n)!}$$\n",
    "$$if\\ n = 7\\ \\&\\ currentDepth = 0\\ (root)\\longrightarrow statesCount = \\dfrac{15!}{8!} = 32,432,400$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
